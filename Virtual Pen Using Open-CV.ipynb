{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work flow/Structure:\n",
    "### STEP1: Find the HSV range of the target Marker/pen and save the values in a .npy file\n",
    "### STEP 2: Use the above values to start drawing in the main code\n",
    "First, we will use color masking to get a mask of our colored pen/marker using the above HSV range.\n",
    "Next, using contour detection we detect and track the location of that pen,i.e get the x,y coordinates.\n",
    "Next, draw a line by joining the x,y coordinates of pen’s previous location (location in the previous frame) with the new x,y points.\n",
    "Add a feature to use the marker as an Eraser to erase unwanted lines.\n",
    "Finally, add another feature to clear the entire Canvas/Screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111, 131, 108], [179, 255, 255]]\n"
     ]
    }
   ],
   "source": [
    "#finding hsv range of target object(pen)\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "# A required callback method that goes into the trackbar function.\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Define a capture device .Here we use our primary laptop camera(0).If using external usb camera use replace 0 with 1.\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,1280)\n",
    "cap.set(4,720)\n",
    "\n",
    "# Create a window named trackbars.\n",
    "cv2.namedWindow(\"Trackbars\")\n",
    "\n",
    "# Now create 6 trackbars that will control the lower and upper range of \n",
    "# H,S and V channels. The Arguments are like this: Name of trackbar, \n",
    "# window name, range,callback function. For Hue the range is 0-179 and\n",
    "# for S,V its 0-255.\n",
    "cv2.createTrackbar(\"L - H\", \"Trackbars\", 0, 179, nothing)\n",
    "cv2.createTrackbar(\"L - S\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"L - V\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"U - H\", \"Trackbars\", 179, 179, nothing)\n",
    "cv2.createTrackbar(\"U - S\", \"Trackbars\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"U - V\", \"Trackbars\", 255, 255, nothing)\n",
    " \n",
    "while True:\n",
    "    \n",
    "    # Start reading the webcam feed frame by frame.\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Flip the frame horizontally (Not required)\n",
    "    frame = cv2.flip( frame, 1 ) \n",
    "    \n",
    "    # Convert the BGR image to HSV image.\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Get the new values of the trackbar in real time as the user changes \n",
    "    # them\n",
    "    l_h = cv2.getTrackbarPos(\"L - H\", \"Trackbars\")\n",
    "    l_s = cv2.getTrackbarPos(\"L - S\", \"Trackbars\")\n",
    "    l_v = cv2.getTrackbarPos(\"L - V\", \"Trackbars\")\n",
    "    u_h = cv2.getTrackbarPos(\"U - H\", \"Trackbars\")\n",
    "    u_s = cv2.getTrackbarPos(\"U - S\", \"Trackbars\")\n",
    "    u_v = cv2.getTrackbarPos(\"U - V\", \"Trackbars\")\n",
    " \n",
    "    # Set the lower and upper HSV range according to the value selected\n",
    "    # by the trackbar\n",
    "    lower_range = np.array([l_h, l_s, l_v])\n",
    "    upper_range = np.array([u_h, u_s, u_v])\n",
    "    \n",
    "    # Filter the image and get the binary mask, where white represents \n",
    "    # your target color\n",
    "    mask = cv2.inRange(hsv, lower_range, upper_range)\n",
    " \n",
    "    # You can also visualize the real part of the target color (Optional)\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "    # Converting the binary mask to 3 channel image, this is just so \n",
    "    # we can stack it with the others\n",
    "    mask_3 = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # stack the mask, orginal frame and the filtered result\n",
    "    stacked = np.hstack((mask_3,frame,res))\n",
    "    \n",
    "    # Show this stacked frame at 40% of the size.\n",
    "    cv2.imshow('Trackbars',cv2.resize(stacked,None,fx=0.4,fy=0.4))\n",
    "    \n",
    "    # If the user presses ESC then exit the program\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "    \n",
    "    # If the user presses `s` then print this array.\n",
    "    if key == ord('s'):\n",
    "        \n",
    "        thearray = [[l_h,l_s,l_v],[u_h, u_s, u_v]]\n",
    "        print(thearray)\n",
    "        \n",
    "        # Also save this array as penval.npy\n",
    "        np.save('hsv_value',thearray)\n",
    "        break\n",
    "    \n",
    "# Release the camera & destroy the windows.    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts Used\n",
    "### Morphological Operations\n",
    "\n",
    "### Basics of Erosion:\n",
    "\n",
    "- Erodes away the boundaries of foreground object\n",
    "- Used to diminish the features of an image.\n",
    "\n",
    "\n",
    "### Working of erosion:\n",
    "\n",
    "\n",
    "1. A kernel(a matrix of odd size(3,5,7) is convolved with the image.\n",
    "2. A pixel in the original image (either 1 or 0) will be considered 1 only if all the pixels under the kernel is 1, otherwise it is eroded (made to zero).\n",
    "3. Thus all the pixels near boundary will be discarded depending upon the size of kernel.\n",
    "4. So the thickness or size of the foreground object decreases or simply white region decreases in the image.\n",
    "\n",
    "\n",
    "### Basics of dilation:\n",
    "\n",
    "- Increases the object area\n",
    "- Used to make features more prominent.\n",
    "\n",
    "\n",
    "### Working of dilation:\n",
    "\n",
    "1. A kernel(a matrix of odd size(3,5,7) is convolved with the image\n",
    "2. A pixel element in the original image is ‘1’ if atleast one pixel under the kernel is ‘1’.\n",
    "3. It increases the white region in the image or size of foreground object increases\n",
    "\n",
    "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/Selection_014.png\">\n",
    "\n",
    "\n",
    "### Practical Usecase\n",
    "Erosion:\n",
    "- It is useful for removing small white noises.\n",
    "- Used to detach two connected objects etc.\n",
    "\n",
    "\n",
    "Dilation:\n",
    "- In cases like noise removal, erosion is followed by dilation. Because, erosion removes white noises, but it also shrinks our object. So we dilate it. Since noise is gone, they won’t come back, but our object area increases.\n",
    "- It is also useful in joining broken parts of an object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contours :\n",
    "Contours are defined as the line joining all the points along the boundary of an image that are having the same intensity. Contours come handy in shape analysis, finding the size of the object of interest, and object detection.\n",
    "\n",
    "### findContours() Method : Arguments\n",
    "- First one is source image, second is contour retrieval mode, third is contour approximation method and it outputs the image, contours, and hierarchy. \n",
    "- ‘contours‘ is a Python list of all the contours in the image. \n",
    "- Each individual contour is a Numpy array of (x, y) coordinates of boundary points of the object.\n",
    "\n",
    "\n",
    "## Hierarchy in Contour Detection\n",
    "\n",
    "<img src=\"https://docs.opencv.org/master/hierarchy.png\">\n",
    "\n",
    "- 0,1,2 are external or outermost. We can say, they are in hierarchy-0 or simply they are in same hierarchy level.\n",
    "- contour-2a can be considered as a child of contour-2 (hierarchy-1.)\n",
    "- contour-3 is child of contour-2 and it comes in next hierarchy.\n",
    "- contours 4,5 are the children of contour-3a, and they come in the last hierarchy.\n",
    "- contour-4 is the first child of contour-3a (It can be contour-5 also).\n",
    "\n",
    "\n",
    "\n",
    "### OpenCV represents it as an array of four values : [Next, Previous, First_Child, Parent]\n",
    "1. Next denotes next contour at the same hierarchical level.\n",
    "\n",
    "For eg, take contour-0 in our picture. Who is next contour in its same level ? It is contour-1. So simply put Next = 1. Similarly for Contour-1, next is contour-2. So Next = 2.\n",
    "contour-2? There is no next contour in the same level. So simply, put Next = -1\n",
    "\n",
    "2. Previous denotes previous contour at the same hierarchical level. \n",
    "For 0 contour it will be -1. For 2 it will be 1.\n",
    "\n",
    "3. First_Child denotes its first child contour.\n",
    "\n",
    "4. Parent denotes index of its parent contour.\n",
    "\n",
    "\n",
    "### Contours Approximation Method :\n",
    "- If we pass cv2.CHAIN_APPROX_NONE, all the boundary points are stored.\n",
    "- cv2.CHAIN_APPROX_SIMPLE removes all redundant points and compresses the contour, thereby saving memory. (ex for a single line)\n",
    "\n",
    "### Contour Retrieval Mode\n",
    "- CV_RETR_EXTERNAL gives \"outer\" contours, so if you have (say) one contour enclosing another (like concentric circles), only the outermost is given. Ex - 0,1,2.\n",
    "- CV_RETR_LIST gives all the contours and doesn't even bother calculating the hierarchy -- good if you only want the contours and don't care whether one is nested inside another.\n",
    "- CV_RETR_CCOMP gives contours and organises them into outer and inner contours. Every contour is either the outline of an object, or the outline of an object inside another object (i.e. hole). The hierarchy is adjusted accordingly. This can be useful if (say) you want to find all holes.\n",
    "\n",
    "<img src=\"https://docs.opencv.org/master/ccomp_hierarchy.png\">\n",
    "\n",
    "- CV_RETR_TREE calculates the full hierarchy of the contours. So you can say that object1 is nested 4 levels deep within object2 and object3 is also nested 4 levels deep.\n",
    "<img src=\"https://docs.opencv.org/master/tree_hierarchy.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "load_from_disk = True\n",
    "if load_from_disk:\n",
    "    hsv_value = np.load('hsv_value.npy')\n",
    "    \n",
    "# Define a capture device .Here we use our primary laptop camera(0).If using external usb camera use replace 0 with 1.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create a window to display the default frame and the threshold frame.\n",
    "cap.set(3,1280)\n",
    "cap.set(4,720)\n",
    "\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "canvas = None\n",
    "x1,y1=0,0\n",
    "noiseth = 800\n",
    "while(1):\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.flip( frame, 1 )\n",
    "    if canvas is None:\n",
    "        canvas = np.zeros_like(frame)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    if load_from_disk:\n",
    "        lower_range = hsv_value[0]\n",
    "        upper_range = hsv_value[1]\n",
    "    else:           \n",
    "        lower_range  = np.array([134, 20, 204])\n",
    "        upper_range = np.array([179, 255, 255])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_range, upper_range)\n",
    "    \n",
    "    mask = cv2.erode(mask,kernel,iterations = 1)\n",
    "    \n",
    "# It erodes away the boundaries of foreground object (Always try to keep foreground in white)\n",
    "# It is normally performed on binary images.\n",
    "# It needs two inputs, one is our original image, second one is called structuring element or kernel which decides \n",
    "#    the nature of operation.\n",
    "# A pixel in the original image (either 1 or 0) will be considered 1 only if all the pixels under the kernel is 1, \n",
    "#    otherwise it is eroded (made to zero).\n",
    "# Iterations: It is number of times erosion is applied.\n",
    "    \n",
    "    mask = cv2.dilate(mask,kernel,iterations = 2)\n",
    "    \n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    \n",
    "    if contours and cv2.contourArea(max(contours,key = cv2.contourArea)) > noiseth:\n",
    "        c = max(contours, key = cv2.contourArea)    \n",
    "        x2,y2,w,h = cv2.boundingRect(c)\n",
    "        if x1 == 0 and y1 == 0:\n",
    "            x1,y1= x2,y2     \n",
    "        else:\n",
    "            canvas = cv2.line(canvas, (x1,y1),(x2,y2), [255,0,0], 4)\n",
    "        x1,y1= x2,y2\n",
    "    else:\n",
    "        x1,y1 =0,0\n",
    "    frame = cv2.add(frame,canvas)\n",
    "    stacked = np.hstack((canvas,frame))\n",
    "    cv2.imshow('VIRTUAL PEN',cv2.resize(stacked,None,fx=0.6,fy=0.6))\n",
    "\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "    if k == ord('c'):\n",
    "        canvas = None\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
